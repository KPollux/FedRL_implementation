{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c082b8c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ae2342",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaa70fb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac940a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE是指从重放缓冲区采样的转换数\n",
    "# GAMMA是上一节中提到的折扣系数\n",
    "# EPS_START是EPSILON的起始值\n",
    "# EPS_END是epsilon的最终值\n",
    "# EPS_DECAY 控制epsilon的指数衰减率，越高意味着衰减越慢\n",
    "# TAU是目标网络的更新率\n",
    "# LR是AdamW优化器的学习率\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "# 动作选取\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    \n",
    "    # 随着进行，eps_threshold逐渐降低\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    \n",
    "    # 常规情况选择价值最高的动作\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    \n",
    "    # 当随机值超过阈值时，随机选取 - exploration\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b28dce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005cf7f7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    # 离线学习，从记忆池中抽取回忆\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    print(transitions)\n",
    "    return\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    \n",
    "    # 将([a, 1], [b, 2], [c, 3])转化为([a, b, c], [1, 2, 3])，一个zip的trick\n",
    "    # 然后将他们分别放到tuples with names里（'state', 'action', 'next_state', and 'reward'）\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    # 计算非最终状态的掩码，并将批处理元素连接起来\n",
    "    # (最终状态是指模拟结束后的状态)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    # 模型计算Q价值，我们根据价值选择动作\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch  # 当前奖励+下一个状态的奖励，更新Q\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66dd0c4f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Perform one step of the optimization (on the policy network)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Soft update of the target network's weights\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# θ′ ← τ θ + (1 −τ )θ′\u001b[39;00m\n\u001b[0;32m     36\u001b[0m target_net_state_dict \u001b[38;5;241m=\u001b[39m target_net\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 离线学习，从记忆池中抽取回忆\u001b[39;00m\n\u001b[0;32m      6\u001b[0m transitions \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39msample(BATCH_SIZE)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# detailed explanation). This converts batch-array of Transitions\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# to Transition of batch-arrays.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 将([a, 1], [b, 2], [c, 3])转化为([a, b, c], [1, 2, 3])，一个zip的trick\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 然后将他们分别放到tuples with names里（'state', 'action', 'next_state', and 'reward'）\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\collections\\__init__.py:458\u001b[0m, in \u001b[0;36mnamedtuple.<locals>.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturn a nicely formatted representation string\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mrepr_fmt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\torch\\_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    423\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    424\u001b[0m     )\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\torch\\_tensor_str.py:637\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    636\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\torch\\_tensor_str.py:568\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    566\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    567\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 568\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    571\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\torch\\_tensor_str.py:328\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\torch\\_tensor_str.py:107\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 107\u001b[0m     tensor_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloating_dtype:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m tensor_view:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get it's state\n",
    "    state, info = env.reset()\n",
    "    # Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    \n",
    "    # count()，它返回一个迭代器，该迭代器从指定数字开始生成无限连续数字\n",
    "    # 默认start=0, step=1\n",
    "    for t in count():\n",
    "        action = select_action(state)  # 选择一个动作\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())  # 执行动作，返回{下一个观察值、奖励、是否结束、是否提前终止}\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)  # 如果没有终止则继续记录下一个状态\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57c8449",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d1f5b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# state, info = env.reset()\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "state, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f02105",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "action = select_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de69b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce9501",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observation, reward, terminated, truncated, _ = env.step(action.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b95c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observation, reward, terminated, truncated, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b81851",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278461d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f4424",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observation, reward, terminated, truncated, _ = env.step(action=0)\n",
    "print(observation, reward, terminated, truncated, _)\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550a1f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "memory.memory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00643df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 离线学习，从记忆池中抽取回忆\n",
    "transitions = memory.sample(BATCH_SIZE)\n",
    "\n",
    "# Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "# detailed explanation). This converts batch-array of Transitions\n",
    "# to Transition of batch-arrays.\n",
    "\n",
    "# 将([a, 1], [b, 2], [c, 3])转化为([a, b, c], [1, 2, 3])，一个zip的trick\n",
    "# 然后将他们分别放到tuples with names里（'state', 'action', 'next_state', and 'reward'）\n",
    "batch = Transition(*zip(*transitions))\n",
    "\n",
    "# Compute a mask of non-final states and concatenate the batch elements\n",
    "# (a final state would've been the one after which simulation ended)\n",
    "# 计算非最终状态的掩码，并将批处理元素连接起来\n",
    "# (最终状态是指模拟结束后的状态)\n",
    "non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                      batch.next_state)), device=device, dtype=torch.bool)\n",
    "non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                            if s is not None])\n",
    "state_batch = torch.cat(batch.state)\n",
    "action_batch = torch.cat(batch.action)\n",
    "reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "# columns of actions taken. These are the actions which would've been taken\n",
    "# for each batch state according to policy_net\n",
    "# 模型计算Q价值，用新模型获取该动作的价值\n",
    "state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "# Compute V(s_{t+1}) for all next states.\n",
    "# Expected values of actions for non_final_next_states are computed based\n",
    "# on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "# This is merged based on the mask, such that we'll have either the expected\n",
    "# state value or 0 in case the state was final.\n",
    "next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "with torch.no_grad():\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "# Compute the expected Q values\n",
    "expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "# Compute Huber loss\n",
    "criterion = nn.SmoothL1Loss()\n",
    "loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "# Optimize the model\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "# In-place gradient clipping\n",
    "torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac317eda",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                      batch.next_state)), device=device, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981a7ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "expected_state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba97c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9c011",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                            if s is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0da3c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_final_next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52709f79",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_batch = torch.cat(batch.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee90ab",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425548f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "action_batch = torch.cat(batch.action)\n",
    "reward_batch = torch.cat(batch.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589ace7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "# columns of actions taken. These are the actions which would've been taken\n",
    "# for each batch state according to policy_net\n",
    "# 模型计算Q价值，我们根据价值选择动作\n",
    "state_action_values = policy_net(state_batch).gather(1, action_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8b5cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "policy_net(state_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d87af9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_action_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f4435",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "policy_net(state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c2698",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b872e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute V(s_{t+1}) for all next states.\n",
    "# Expected values of actions for non_final_next_states are computed based\n",
    "# on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "# This is merged based on the mask, such that we'll have either the expected\n",
    "# state value or 0 in case the state was final.\n",
    "next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "with torch.no_grad():\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "# Compute the expected Q values\n",
    "expected_state_action_values = (next_state_values * GAMMA) + reward_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947827a5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "expected_state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "68182a6a-80b6-4a04-8179-900775e3f5d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [382]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m     43\u001b[0m             episode_durations\u001b[38;5;241m.\u001b[39mappend(t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m             \u001b[43mplot_durations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComplete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mplot_durations\u001b[1;34m(show_result)\u001b[0m\n\u001b[0;32m     66\u001b[0m     means \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m99\u001b[39m), means))\n\u001b[0;32m     67\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(means\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m---> 69\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pause a bit so that plots are updated\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_ipython:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m show_result:\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\pyplot.py:546\u001b[0m, in \u001b[0;36mpause\u001b[1;34m(interval)\u001b[0m\n\u001b[0;32m    544\u001b[0m canvas \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[1;32m--> 546\u001b[0m     \u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m show(block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    548\u001b[0m canvas\u001b[38;5;241m.\u001b[39mstart_event_loop(interval)\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\backend_bases.py:2060\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[0;32m   2059\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[1;32m-> 2060\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:436\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m RendererAgg\u001b[38;5;241m.\u001b[39mlock, \\\n\u001b[0;32m    434\u001b[0m      (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    435\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 73\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     75\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2807\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 2810\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   2814\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3079\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m   3080\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n\u001b[1;32m-> 3082\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3085\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\axis.py:1158\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[1;32m-> 1158\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1159\u001b[0m ticklabelBoxes, ticklabelBoxes2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m   1160\u001b[0m                                                         renderer)\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\axis.py:1045\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_ticks\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    Update ticks (position and labels) using the current data interval of\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m    the axes.  Return the list of ticks that will be drawn.\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1045\u001b[0m     major_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_majorticklocs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1046\u001b[0m     major_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mformat_ticks(major_locs)\n\u001b[0;32m   1047\u001b[0m     major_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_major_ticks(\u001b[38;5;28mlen\u001b[39m(major_locs))\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\axis.py:1277\u001b[0m, in \u001b[0;36mAxis.get_majorticklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_majorticklocs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;124;03m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\ticker.py:2114\u001b[0m, in \u001b[0;36mMaxNLocator.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   2113\u001b[0m     vmin, vmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\u001b[38;5;241m.\u001b[39mget_view_interval()\n\u001b[1;32m-> 2114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\ticker.py:2122\u001b[0m, in \u001b[0;36mMaxNLocator.tick_values\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2119\u001b[0m     vmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mvmax\n\u001b[0;32m   2120\u001b[0m vmin, vmax \u001b[38;5;241m=\u001b[39m mtransforms\u001b[38;5;241m.\u001b[39mnonsingular(\n\u001b[0;32m   2121\u001b[0m     vmin, vmax, expander\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-13\u001b[39m, tiny\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-14\u001b[39m)\n\u001b[1;32m-> 2122\u001b[0m locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2124\u001b[0m prune \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prune\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prune \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\ticker.py:2061\u001b[0m, in \u001b[0;36mMaxNLocator._raw_ticks\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nbins \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   2060\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2061\u001b[0m         nbins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tick_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2062\u001b[0m                         \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_n_ticks \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m   2063\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2064\u001b[0m         nbins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\axis.py:2262\u001b[0m, in \u001b[0;36mXAxis.get_tick_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tick_space\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 2262\u001b[0m     ends \u001b[38;5;241m=\u001b[39m \u001b[43mmtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bounds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2263\u001b[0m     ends \u001b[38;5;241m=\u001b[39m ends\u001b[38;5;241m.\u001b[39mtransformed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mtransAxes \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m   2264\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi_scale_trans)\n\u001b[0;32m   2265\u001b[0m     length \u001b[38;5;241m=\u001b[39m ends\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m72\u001b[39m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\transforms.py:820\u001b[0m, in \u001b[0;36mBbox.from_bounds\u001b[1;34m(x0, y0, width, height)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_bounds\u001b[39m(x0, y0, width, height):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;124;03m    Create a new `Bbox` from *x0*, *y0*, *width* and *height*.\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m    *width* and *height* may be negative.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_extents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\transforms.py:839\u001b[0m, in \u001b[0;36mBbox.from_extents\u001b[1;34m(minpos, *args)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_extents\u001b[39m(\u001b[38;5;241m*\u001b[39margs, minpos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;124;03m    Create a new Bbox from *left*, *bottom*, *right* and *top*.\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m       scales where negative bounds result in floating point errors.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 839\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43mBbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m minpos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    841\u001b[0m         bbox\u001b[38;5;241m.\u001b[39m_minpos[:] \u001b[38;5;241m=\u001b[39m minpos\n",
      "File \u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\matplotlib\\transforms.py:785\u001b[0m, in \u001b[0;36mBbox.__init__\u001b[1;34m(self, points, **kwargs)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;66;03m# it is helpful in some contexts to know if the bbox is a\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# default or has been mutated; we store the orig points to\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;66;03m# support the mutated methods\u001b[39;00m\n\u001b[1;32m--> 785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_points_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get it's state\n",
    "    state, info = env.reset()\n",
    "    # Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    \n",
    "    # count()，它返回一个迭代器，该迭代器从指定数字开始生成无限连续数字\n",
    "    # 默认start=0, step=1\n",
    "    for t in count():\n",
    "        action = select_action(state)  # 选择一个动作\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())  # 执行动作，返回{下一个观察值、奖励、是否结束、是否提前终止}\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)  # 如果没有终止则继续记录下一个状态\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7429aa36-028e-496d-9c38-4c7b8c94aef5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02910686,  0.02321897, -0.03120922,  0.04507666], dtype=float32)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b0582069-0886-419b-95bd-d95e56808e22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0291,  0.0232, -0.0312,  0.0451]], device='cuda:0'), {})"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state, info = env.reset()\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "state, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d4b86bcc-840f-47c1-9ce0-3e8fb9d4fe70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "action = select_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "29f28afc-b9ac-4b4f-8de3-493781c10e14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5a706d62-f760-466a-b8de-6c3782ecd7b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observation, reward, terminated, truncated, _ = env.step(action.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0591d0a7-593e-4468-8308-f0c77e2defbb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02864248, -0.17144188, -0.03030769,  0.32775173], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation, reward, terminated, truncated, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "880bd402-e9ca-4f06-8177-6178ac00d5d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0487914 , -0.04999217,  0.01997874, -0.01379636], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61267eed-43fa-4ac9-a30e-429aa31c310b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "102bb595-517d-4b1f-9196-938fb9496c2c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2112378   0.49399808 -1.6252303  -5.165769  ] 0.0 True False {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13c5b136040>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUa0lEQVR4nO3dbYxed5nf8e9vHjxOCIWEjCNjO02gptoEtQ4ahZWoumlCSTataqjEykiFVIpkXgSVqCu6ya5U2BeW2GohfdECCiVai0ISbwFhUfYhZEGI1ZZgwJg4IYshXmJsbCfhIU6wPQ9XX9zH+I4zY4/nIeP/zPcjHZ1zX+ec+1x/J/n55D/nnjtVhSSpHQNL3YAk6fwY3JLUGINbkhpjcEtSYwxuSWqMwS1JjVm04E5yS5InkuxLctdiXUeSVposxnPcSQaBvwf+NXAA+Bbwrqp6bMEvJkkrzGLdcV8P7KuqH1fVSeABYPMiXUuSVpShRXrfdcBTfa8PAG+e6eDLL7+8rrrqqkVqRZLas3//fp5++ulMt2+xgnu6i71oTibJVmArwJVXXsmuXbsWqRVJas/Y2NiM+xZrquQAsKHv9XrgYP8BVXVvVY1V1djo6OgitSFJy89iBfe3gI1Jrk6yCtgC7Fyka0nSirIoUyVVNZHkfcBfAYPAfVW1dzGuJUkrzWLNcVNVXwa+vFjvL0krlZ+clKTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktQYg1uSGmNwS1JjDG5JaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUmHl9dVmS/cBzwCQwUVVjSS4DHgSuAvYDv1dVP59fm5KkUxbijvtfVdWmqhrrXt8FPFxVG4GHu9eSpAWyGFMlm4Ht3fZ24O2LcA1JWrHmG9wF/HWSbyfZ2tWuqKpDAN16zTyvIUnqM685buAtVXUwyRrgoSQ/mO2JXdBvBbjyyivn2YYkrRzzuuOuqoPd+gjwBeB64HCStQDd+sgM595bVWNVNTY6OjqfNiRpRZlzcCd5RZJXntoG3gY8CuwEbusOuw344nyblCSdNp+pkiuALyQ59T6fraq/TPItYEeS24GfAO+cf5uSpFPmHNxV9WPgn09Tfwa4aT5NSZJm5icnJakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktQYg1uSGmNwS1JjDG5JaozBLUmNMbglqTEGtyQ1xuCWpMacM7iT3JfkSJJH+2qXJXkoyQ+79aV9++5Osi/JE0luXqzGJWmlms0d958Bt5xRuwt4uKo2Ag93r0lyDbAFuLY752NJBhesW0nSuYO7qr4OPHtGeTOwvdveDry9r/5AVZ2oqieBfcD1C9OqJAnmPsd9RVUdAujWa7r6OuCpvuMOdLWXSLI1ya4ku44ePTrHNiRp5VnoH05mmlpNd2BV3VtVY1U1Njo6usBtSNLyNdfgPpxkLUC3PtLVDwAb+o5bDxyce3uSpDPNNbh3Ard127cBX+yrb0kykuRqYCPwyPxalCT1GzrXAUnuB24ALk9yAPgg8GFgR5LbgZ8A7wSoqr1JdgCPARPAHVU1uUi9S9KKdM7grqp3zbDrphmO3wZsm09TkqSZ+clJSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktQYg1uSGmNwS1JjDG5JaozBLUmNOWdwJ7kvyZEkj/bVPpTkp0l2d8utffvuTrIvyRNJbl6sxiVppZrNHfefAbdMU7+nqjZ1y5cBklwDbAGu7c75WJLBhWpWkjSL4K6qrwPPzvL9NgMPVNWJqnoS2AdcP4/+JElnmM8c9/uS7OmmUi7tauuAp/qOOdDVXiLJ1iS7kuw6evToPNqQpJVlrsH9ceD1wCbgEPCRrp5pjq3p3qCq7q2qsaoaGx0dnWMbkrTyzCm4q+pwVU1W1RTwSU5PhxwANvQduh44OL8WJUn95hTcSdb2vXwHcOqJk53AliQjSa4GNgKPzK9FSVK/oXMdkOR+4Abg8iQHgA8CNyTZRG8aZD/wXoCq2ptkB/AYMAHcUVWTi9K5JK1Q5wzuqnrXNOVPneX4bcC2+TQlSZqZn5yUpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktSYcwZ3kg1Jvprk8SR7k7y/q1+W5KEkP+zWl/adc3eSfUmeSHLzYg5Aklaa2dxxTwC/X1W/Bfw2cEeSa4C7gIeraiPwcPeabt8W4FrgFuBjSQYXo3lJWonOGdxVdaiqvtNtPwc8DqwDNgPbu8O2A2/vtjcDD1TViap6EtgHXL/AfUvSinVec9xJrgKuA74JXFFVh6AX7sCa7rB1wFN9px3oame+19Yku5LsOnr06Bxal6SVadbBneQS4HPAnVX1q7MdOk2tXlKoureqxqpqbHR0dLZtSNKKN6vgTjJML7Q/U1Wf78qHk6zt9q8FjnT1A8CGvtPXAwcXpl1J0myeKgnwKeDxqvpo366dwG3d9m3AF/vqW5KMJLka2Ag8snAtS9LKNjSLY94CvBv4fpLdXe0PgQ8DO5LcDvwEeCdAVe1NsgN4jN4TKXdU1eRCNy5JK9U5g7uqvsH089YAN81wzjZg2zz6kiTNwE9OSlJjDG5JaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqzGy+LHhDkq8meTzJ3iTv7+ofSvLTJLu75da+c+5Osi/JE0luXswBSNJKM5svC54Afr+qvpPklcC3kzzU7bunqv60/+Ak1wBbgGuB1wJfSfIGvzBYkhbGOe+4q+pQVX2n234OeBxYd5ZTNgMPVNWJqnoS2AdcvxDNSpLOc447yVXAdcA3u9L7kuxJcl+SS7vaOuCpvtMOcPaglySdh1kHd5JLgM8Bd1bVr4CPA68HNgGHgI+cOnSa02ua99uaZFeSXUePHj3fviVpxZpVcCcZphfan6mqzwNU1eGqmqyqKeCTnJ4OOQBs6Dt9PXDwzPesqnuraqyqxkZHR+czBklaUWbzVEmATwGPV9VH++pr+w57B/Bot70T2JJkJMnVwEbgkYVrWZJWttk8VfIW4N3A95Ps7mp/CLwrySZ60yD7gfcCVNXeJDuAx+g9kXKHT5RI0sI5Z3BX1TeYft76y2c5ZxuwbR59SZJm4CcnJakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxhjcktSY2fx2QEkrVFWxZ88enn/++ZflesPDw7zpTW9icHDwZbleqwxuSTOqKt7znvewZ8+el+V6a9as4Uc/+hGXXHLJy3K9Vhnckl6iqqCKmppkeHCAkeFBBgbCQLql2x4eGuTi1cNcvHqYV6we5uKRYVa94rWMXDrGwMAQl+aHvHrV03zq/36HY78+udTDWjYMbmkZqDr1ta7VfcNrdat6ca2mmJoYZ3L8OFPjJ3vriRNMjZ9gcvwEU+PHT68nevv/442v4/ibR7loZJiLVw9x0cgwF40M84qRYVYND5Kk9wv7E341Ocr3nnsbJ7mEEIZygn+6+mE++9D3De4FZHBLS+R02E679/TW1BRTEyenXSYnTvaCd+JkL3xPHu9C+fhvtn9TO3mcyfFfUzXVu5t+0XqKmjpd67/+mze+BnjNOcczWYM8fuwmxvOPfvPNKxOs5vvHfocT9T+Al2eefCUwuKUFVt0Uw9TkODUxztRkb6nJcaYmJvq2T/YF66+ZPHk6XF9UmzhJTU12yxRV3Xpqshe0Xb0/bJfKZA1PW6ua7ku0NFfnDO4kq4GvAyPd8f+nqj6Y5DLgQeAqet85+XtV9fPunLuB24FJ4D9V1V8tSvfSBejQ7r/kF/u/S01OMjU1QU1OdEE+QU1NUJOTvfXU8voq1lCsHjjG8akX/2BxZOB5BjK1RF0tT7O54z4B3FhVx5IMA99I8hfAvwcerqoPJ7kLuAv4gyTXAFuAa4HXAl9J8ga/MFgrxYlfHuH5I/uXuo2X3UCm2PTKv2H3czfxy4nLgXDx4C/5rYsfYtXAr5e6vWVlNl8WXMCx7uVwtxSwGbihq28Hvgb8QVd/oKpOAE8m2QdcD/zdTNcYHx/nZz/72dxGIF1gjj77S5795QtL3cbL4uTEJC8cH+f54+O8cHycF06c5Ocv7OUnz43y/PFJRib/gb89/nOee2F2P5icmpri8OHDHDt27NwHL3Pj4+Mz7pvVHHeSQeDbwD8B/mdVfTPJFVV1CKCqDiVZ0x2+Dvh/facf6GozeuaZZ/j0pz89m1akC96zP961RHfcIb3HO+g2IKH3zEe68gAZWsXg8AgDQyO99fDqbt17PTi8mgwOk/R+TvmJT3yCw4cPz3jVqqKq9xxL7ynC3hMtvUcKz2/m/fjx49x///2MjIzM/Y9hmXjmmWdm3Der4O6mOTYleTXwhSRvPMvh0/0U4iX/7JJsBbYCXHnllXzgAx+YTSvSBe/Jr23n6Sf+dh7vkBdtJgMMDI0wMLSKgeFVvXX3enDo1OtVveBddRGDXRAPrrqoF8qrVne11QwMj5CBwV6gJyQD3faL172/BMLU1BT3P/jn/MNTP53vH8usXHzxxdx5551+AAd48MEHZ9x3Xk+VVNUvknwNuAU4nGRtd7e9FjjSHXYA2NB32nrg4DTvdS9wL8DY2NjS/zhcWkAZGGJgaJgMDjEwuIqBwSEyNMzAYG85tT246qLTYbtqNYPDF/XWq3rrgeHVDAytIgODvbvlgUEyMEDSW9NXB0h8emMlmM1TJaPAeBfaFwFvBf4E2AncBny4W3+xO2Un8NkkH6X3w8mNwCOL0Lt0QVp73e+y5prfIYODZGCIDAz2gntg6EW1XhgbtDp/s7njXgts7+a5B4AdVfWlJH8H7EhyO/AT4J0AVbU3yQ7gMWACuMMnSrSSrH7VmnMfJM3DbJ4q2QNcN039GeCmGc7ZBmybd3eSpJfw93FLUmMMbklqjL+rRNKMknDjjTfyute97mW53qte9Sq/RGEWDG5JM0rCPffcs9Rt6AxOlUhSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxpwzuJOsTvJIku8l2Zvkj7v6h5L8NMnubrm175y7k+xL8kSSmxdzAJK00szm93GfAG6sqmNJhoFvJPmLbt89VfWn/QcnuQbYAlxL71vev5LkDX5hsCQtjHPecVfPse7lcLfUWU7ZDDxQVSeq6klgH3D9vDuVJAGznONOMphkN3AEeKiqvtntel+SPUnuS3JpV1sHPNV3+oGuJklaALMK7qqarKpNwHrg+iRvBD4OvB7YBBwCPtIdnune4sxCkq1JdiXZdfTo0Tm0Lkkr03k9VVJVvwC+BtxSVYe7QJ8CPsnp6ZADwIa+09YDB6d5r3uraqyqxkZHR+fSuyStSLN5qmQ0yau77YuAtwI/SLK277B3AI922zuBLUlGklwNbAQeWdCuJWkFm81TJWuB7UkG6QX9jqr6UpJPJ9lEbxpkP/BegKram2QH8BgwAdzhEyWStHDOGdxVtQe4bpr6u89yzjZg2/xakyRNx09OSlJjDG5JaozBLUmNMbglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWqMwS1JjTG4JakxBrckNcbglqTGGNyS1BiDW5IaY3BLUmMMbklqjMEtSY0xuCWpMQa3JDXG4JakxqSqlroHkhwFngeeXupeFsHlOK7WLNexOa62/OOqGp1uxwUR3ABJdlXV2FL3sdAcV3uW69gc1/LhVIkkNcbglqTGXEjBfe9SN7BIHFd7luvYHNcyccHMcUuSZudCuuOWJM3Ckgd3kluSPJFkX5K7lrqf85XkviRHkjzaV7ssyUNJftitL+3bd3c31ieS3Lw0XZ9bkg1Jvprk8SR7k7y/qzc9tiSrkzyS5HvduP64qzc9rlOSDCb5bpIvda+Xy7j2J/l+kt1JdnW1ZTG2OamqJVuAQeBHwOuAVcD3gGuWsqc5jOFfAm8CHu2r/Tfgrm77LuBPuu1rujGOAFd3Yx9c6jHMMK61wJu67VcCf9/13/TYgACXdNvDwDeB3259XH3j+8/AZ4EvLZd/F7t+9wOXn1FbFmOby7LUd9zXA/uq6sdVdRJ4ANi8xD2dl6r6OvDsGeXNwPZuezvw9r76A1V1oqqeBPbR+zO44FTVoar6Trf9HPA4sI7Gx1Y9x7qXw91SND4ugCTrgX8D/K++cvPjOovlPLazWurgXgc81ff6QFdr3RVVdQh6AQis6epNjjfJVcB19O5Omx9bN52wGzgCPFRVy2JcwH8H/gsw1VdbDuOC3l+uf53k20m2drXlMrbzNrTE1880teX8mEtz401yCfA54M6q+lUy3RB6h05TuyDHVlWTwKYkrwa+kOSNZzm8iXEl+bfAkar6dpIbZnPKNLULblx93lJVB5OsAR5K8oOzHNva2M7bUt9xHwA29L1eDxxcol4W0uEkawG69ZGu3tR4kwzTC+3PVNXnu/KyGBtAVf0C+BpwC+2P6y3Av0uyn96U441J/jftjwuAqjrYrY8AX6A39bEsxjYXSx3c3wI2Jrk6ySpgC7BziXtaCDuB27rt24Av9tW3JBlJcjWwEXhkCfo7p/RurT8FPF5VH+3b1fTYkox2d9okuQh4K/ADGh9XVd1dVeur6ip6/x39TVX9BxofF0CSVyR55alt4G3AoyyDsc3ZUv90FLiV3hMLPwL+aKn7mUP/9wOHgHF6f9PfDrwGeBj4Ybe+rO/4P+rG+gTwu0vd/1nG9S/o/e/lHmB3t9za+tiAfwZ8txvXo8B/7epNj+uMMd7A6adKmh8XvafOvtcte0/lxHIY21wXPzkpSY1Z6qkSSdJ5MrglqTEGtyQ1xuCWpMYY3JLUGINbkhpjcEtSYwxuSWrM/wdu1sBKJlJfgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "observation, reward, terminated, truncated, _ = env.step(action=0)\n",
    "print(observation, reward, terminated, truncated, _)\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "2e9d631d-cbba-4a26-bd82-9678b5b60310",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transition(state=tensor([[-0.0233,  0.0287, -0.0338,  0.0419]], device='cuda:0'), action=tensor([[0]], device='cuda:0'), next_state=tensor([[-0.0228, -0.1659, -0.0330,  0.3237]], device='cuda:0'), reward=tensor([1.], device='cuda:0'))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.memory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "7c0cba63-3ca9-45c2-9519-859b1a5c787d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 离线学习，从记忆池中抽取回忆\n",
    "transitions = memory.sample(BATCH_SIZE)\n",
    "\n",
    "# Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "# detailed explanation). This converts batch-array of Transitions\n",
    "# to Transition of batch-arrays.\n",
    "\n",
    "# 将([a, 1], [b, 2], [c, 3])转化为([a, b, c], [1, 2, 3])，一个zip的trick\n",
    "# 然后将他们分别放到tuples with names里（'state', 'action', 'next_state', and 'reward'）\n",
    "batch = Transition(*zip(*transitions))\n",
    "\n",
    "# Compute a mask of non-final states and concatenate the batch elements\n",
    "# (a final state would've been the one after which simulation ended)\n",
    "# 计算非最终状态的掩码，并将批处理元素连接起来\n",
    "# (最终状态是指模拟结束后的状态)\n",
    "non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                      batch.next_state)), device=device, dtype=torch.bool)\n",
    "non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                            if s is not None])\n",
    "state_batch = torch.cat(batch.state)\n",
    "action_batch = torch.cat(batch.action)\n",
    "reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "# columns of actions taken. These are the actions which would've been taken\n",
    "# for each batch state according to policy_net\n",
    "# 模型计算Q价值，用新模型获取该动作的价值\n",
    "state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "# Compute V(s_{t+1}) for all next states.\n",
    "# Expected values of actions for non_final_next_states are computed based\n",
    "# on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "# This is merged based on the mask, such that we'll have either the expected\n",
    "# state value or 0 in case the state was final.\n",
    "next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "with torch.no_grad():\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "# Compute the expected Q values\n",
    "expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "# Compute Huber loss\n",
    "criterion = nn.SmoothL1Loss()\n",
    "loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "# Optimize the model\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "# In-place gradient clipping\n",
    "torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b800577d-4abb-4718-bd19-f6b88b839516",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                      batch.next_state)), device=device, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "70369de2-e77a-41f4-ba84-b026284f46ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.4685, 7.5888, 5.1479, 7.5660, 5.9330, 7.4581, 7.2448, 6.7880, 5.9606,\n",
       "        7.5637, 7.0031, 6.9689, 7.1340, 5.8712, 7.3322, 7.5842, 7.2930, 7.2360,\n",
       "        7.2499, 5.5415, 7.3471, 6.5772, 7.0785, 7.0665, 5.9190, 6.8712, 7.2400,\n",
       "        6.9631, 6.8432, 7.2814, 7.5040, 7.4899, 6.9857, 6.7736, 6.8589, 5.7544,\n",
       "        6.8182, 6.6367, 6.3705, 7.0976, 7.6036, 7.1072, 6.8947, 7.2691, 7.6142,\n",
       "        7.2929, 7.0001, 7.2842, 6.7713, 6.6714, 6.5645, 7.0242, 6.8082, 7.4647,\n",
       "        6.9367, 6.7906, 6.1358, 7.2860, 1.0000, 6.8334, 7.5121, 6.8580, 6.7377,\n",
       "        1.0000, 1.0000, 5.4180, 7.2098, 7.1266, 6.8639, 5.1328, 7.6238, 1.0000,\n",
       "        7.4275, 6.6213, 1.0000, 6.8631, 6.6035, 6.1322, 1.0000, 7.0059, 6.9815,\n",
       "        7.2889, 6.8302, 7.3879, 7.0465, 5.9096, 1.0000, 6.9434, 6.8958, 7.0224,\n",
       "        1.0000, 6.7460, 7.5635, 4.9501, 6.8201, 6.8144, 7.0029, 6.5784, 6.7841,\n",
       "        1.0000, 7.5977, 5.4831, 5.9192, 7.6092, 7.5945, 7.5447, 7.1573, 1.0000,\n",
       "        6.0147, 6.6845, 6.9649, 7.3711, 7.6701, 6.9544, 6.6120, 7.0415, 7.5782,\n",
       "        6.9466, 7.2078, 6.8001, 7.2278, 6.2423, 6.9025, 7.0640, 6.9244, 7.5507,\n",
       "        6.8792, 7.0149], device='cuda:0')"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "55a79d02-90e0-456a-b9ae-8c79b7f165d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "f30b0715-b13b-41ce-b2c2-bec48149fa8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                            if s is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8c0ab-1b10-4a9d-a0bd-576554161926",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_final_next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e2a28-c53a-40f1-b084-4a898f1cb145",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_batch = torch.cat(batch.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1fbbade7-03de-462b-b12d-c8c3519ec2df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "82a8a509-3410-4571-bf5d-417f06e3cb8f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "action_batch = torch.cat(batch.action)\n",
    "reward_batch = torch.cat(batch.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6764a151-6343-40f2-baac-ae8cb15448f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "# columns of actions taken. These are the actions which would've been taken\n",
    "# for each batch state according to policy_net\n",
    "# 模型计算Q价值，我们根据价值选择动作\n",
    "state_action_values = policy_net(state_batch).gather(1, action_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "72373806-9d2e-47a7-a68a-af8b3e630f04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(state_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "74622973-3c79-4227-b8aa-48d90f5f1728",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e226601a-99b2-413a-9fd4-dc8d9ab57567",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "policy_net(state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45372841-25c9-4dbe-b057-781b5a3ccd94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "c1424958-7183-47c3-9e44-5993d0e234a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute V(s_{t+1}) for all next states.\n",
    "# Expected values of actions for non_final_next_states are computed based\n",
    "# on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "# This is merged based on the mask, such that we'll have either the expected\n",
    "# state value or 0 in case the state was final.\n",
    "next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "with torch.no_grad():\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "# Compute the expected Q values\n",
    "expected_state_action_values = (next_state_values * GAMMA) + reward_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "f9f1cb46-af5f-4083-9f06-63627517aea8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6940, 7.6320, 1.0000, 6.8931, 7.2965, 1.0000, 7.3674, 7.2636, 7.0829,\n",
       "        6.8665, 5.3040, 7.5476, 7.2775, 6.9221, 6.7483, 7.2926, 7.3596, 7.5882,\n",
       "        7.0033, 1.0000, 6.7918, 6.9560, 7.3211, 7.4033, 6.4431, 5.9812, 7.3971,\n",
       "        7.3469, 7.2444, 6.4381, 6.2376, 6.8276, 7.0640, 6.7911, 7.4468, 7.1032,\n",
       "        6.6925, 6.1211, 7.3502, 6.7021, 6.9573, 7.5754, 6.3811, 7.5550, 7.3111,\n",
       "        7.1066, 7.2401, 7.1919, 5.4027, 7.0654, 5.6699, 7.3805, 6.9878, 6.5281,\n",
       "        7.5751, 7.2383, 7.3820, 5.0600, 7.6216, 5.6560, 6.9893, 5.6101, 7.6117,\n",
       "        7.3134, 6.9264, 5.3139, 7.1292, 7.5755, 7.2406, 7.3032, 7.4953, 6.7677,\n",
       "        1.0000, 6.8479, 5.6185, 6.9304, 6.2801, 5.7533, 7.2865, 1.0000, 6.9040,\n",
       "        7.5365, 6.7026, 6.2948, 7.4916, 5.9664, 6.9866, 7.2873, 7.3358, 7.5377,\n",
       "        7.5519, 7.0465, 5.4180, 6.8106, 6.9236, 7.3559, 6.8518, 6.9213, 7.5774,\n",
       "        7.2789, 5.1925, 6.6714, 6.4643, 6.7012, 7.3640, 7.4462, 1.0000, 7.2996,\n",
       "        5.9282, 5.6381, 6.8009, 7.4647, 6.3024, 7.3338, 7.5939, 6.7841, 7.2986,\n",
       "        7.5183, 7.4676, 5.4129, 6.9616, 7.5799, 6.8489, 1.0000, 7.1006, 7.5706,\n",
       "        6.2715, 6.8712], device='cuda:0')"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bd4a5-cdfa-42ec-b8a9-47534c1c1c87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
